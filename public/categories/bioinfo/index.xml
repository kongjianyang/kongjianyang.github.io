<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>-bioinfo on KJY</title>
    <link>https://kongjianyang.github.io/categories/bioinfo/</link>
    <description>Recent content in -bioinfo on KJY</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Aug 2023 15:58:44 -0700</lastBuildDate><atom:link href="https://kongjianyang.github.io/categories/bioinfo/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>生存分析入门</title>
      <link>https://kongjianyang.github.io/cn/2023/08/08/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 08 Aug 2023 15:58:44 -0700</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2023/08/08/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90/</guid>
      <description>作为临床分析中的重要一环，今天入门生存分析。
生存分析（survival analysis）是生物医学研究中常用的分析方法。在队列随访研究中，我们会事先定义一些观察终点，比如肿瘤复发、患者死亡、血压达标等，这些终点称为事件（event）。从研究开始到发生事件的时间间隔称为生存时间（survival time）。
由于生存时间数据具有以下两个特点，所以提出生存分析这一特殊的分析方法：
（1）偏态分布：生存时间通常具有明显的偏态分布，有正态分布假设的统计方法不能适用。 （2）删失（censoring）：研究对象在观察时间内没有发生事件称为删失。一种情况是研究对象在中途失访或退出，导致没有观察到事件；另一种情况是超过了最长的随访时间事件仍未发生。删失数据是一种不完整数据，是生成分析独有的重要组成部分。
生存分析使用的方法：
 Kaplan-Meier plots to visualize survival curves（根据生存时间分布，估计生存率以及中位生存时间，以生存曲线方式展示，从而分析生存特征，一般用Kaplan-Meier法，还有寿命法） Log-rank test to compare the survival curves of two or more groups（通过比较两组或者多组之间的的生存曲线，一般是生存率及其标准误，从而研究之间的差异，一般用log rank检验） Cox proportional hazards regression to describe the effect of variables on survival（用Cox风险比例模型来分析变量对生存的影响，可以两个及两个以上的因素，很常用）  所以一般做生存分析，可以用KM（Kaplan-Meier）方法估计生存率，做生存曲线，然后可以根据分组检验一下多组间生存曲线是否有显著的差异，最后用Cox风险比例模型来研究下某个因素对生存的影响
Kaplan-Meier生存曲线估计 在t检验或回归分析中，我们估计的是研究对象的一些参数，比如均值、标准差、回归系数等。而在生存分析中，我们得到的不是单个特定的数值，而是一条曲线，称为生存曲线（survival curve）。曲线对应的函数称为生存函数（survival function），用S(t)表示，其定义为：
S(t)是个体生存超过时间t的概率
以时间t为横坐标，S(t)为纵坐标，绘制出来的曲线就是生存曲线。生存曲线具有两个特点：
（1）显然，在观察开始的时候，所有个体都是存活的，所以S(t=0)=1； （2）时间越长，生存的概率越小，所以S(t)是递减的。
表1展示了KM法的计算过程。
表1一共包含5列，最后两列可以通过前三列计算出来。第一列是生存时间t，注意不包含删失的时间，但包含时间0。第二列是t时刻事件发生个体数，可以看到大部分数据为1。第三列是t时刻仍然存活的个体数。
前三行准备好后，第四行就是一个简单的数学计算。除了第一行外，其余各行的第五列等于上一行的第五列乘以本行的第四列。
假设检验Log-rank 在很多情况下，我们需要比较两组生存曲线之间有无差别，比如某种新药组的患者生存率是否比常规药物组要高。一种容易想到的方法是指定一个时间点，比如2年，分别计算出两组生存时间超过2年的个案数，然后进行2×2列联表的χ2检验。这个方法有两个明显的缺点：一是由于删失的存在，难以准确计算生存率；二是时间长度可以随意指定，带来分析结果的偏差。
Log-rank检验的零假设是两组生存曲线一样的。如果零假设成立，那么两组内的事件发生个体数之比应该等于两组样本数之比，由此计算出事件发生的期望数。Log-rank方法就是分别将两组所有时间点的期望数加起来，与所有观察数进行比较。
Cox比例风险回归模型 在临床研究中，有许多情况，其中几个已知量（称为 协变量covariates）可能会影响患者的预后。
例如，假设比较了两组患者：有和没有特定基因型的患者。如果其中一组还包含较年长的个体，则生存率的任何差异都可能归因于基因型或年龄，或两者都有。因此，在调查与任何一个因素相关的生存率时，通常需要针对其他因素的影响进行调整。
Cox模型的目的是同时评估几个因素对生存的影响。换句话说，它允许我们检查特定因素如何影响特定时间点特定事件（例如，感染，死亡）的发生率。该比率通常称为风险比率。
Cox模型与Kaplan-Meier法：
Kaplan-Meier法是非参数法，而Cox模型是半参数法，一般来说在符合一定条件下，后者的检验效应要大于前者 Kaplan-Meier法一般处理单因素对研究生存结局的影响，而Cox模型可以同时处理多个因素对生存结局的影响
当预测变量为分类变量时（例如：治疗A与治疗B；男性与女性），Kaplan-Meier曲线和对数秩检验才有用。对于定量预测指标（例如基因表达，体重或年龄），它们并不容易工作。
一种替代方法是Cox比例风险回归分析，它既适用于定量预测变量也适用于类别变量。此外，Cox回归模型扩展了生存分析方法，可以同时评估几种风险因素对生存时间的影响。
R语言分析 # 确保在导入前安装好 library(survival) library(dplyr) library(survminer) library(tidyverse) 我们将使用的核心函数包括：</description>
    </item>
    
    <item>
      <title>Single_cell_sequencing入门</title>
      <link>https://kongjianyang.github.io/cn/2022/05/23/scrna/</link>
      <pubDate>Mon, 23 May 2022 16:03:40 -0600</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2022/05/23/scrna/</guid>
      <description>Reference:
https://broadinstitute.github.io/KrumlovSingleCellWorkshop2020/index.html https://satijalab.org/seurat/articles/pbmc3k_tutorial.html#finding-differentially-expressed-features-cluster-biomarkers- https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html Background 单细胞RNA-seq能够独立地提供每个细胞的RNA表达谱，并鉴定异质细胞群中的稀有细胞。尽管肿瘤异质性可归因于累积突变，但即使是遗传上相同的细胞在相同环境下也可能表现出基因和蛋白表达水平的差异，从而导致耐药性的产生。单细胞RNA-seq就能够发现这些稀有个体。
单细胞RNA-seq的流程
当然，单细胞RNA-seq的开展绝非易事，需要用到一系列尖端技术。大家首先要高效分离单细胞，然后进行RNA提取、逆转录、文库制备和测序，最后再通过生物信息学软件进行数据分析。其中，第一步 – 单细胞分离就相当棘手。
单细胞分离 从异质性的细胞群体中分离单细胞，目前的选择有不少，新方法也在不断面世。选择分离方法时，您可能需要考虑它是高通量还是低通量，以及是盲选还是有偏向的选择（基于某个参数）。
一些高通量的技术，比如最常用的荧光激活细胞分选（FACS）和磁性激活细胞分选（MACS），可根据细胞的大小/形状或细胞表面标志物的表达进行有偏向的选择，而基于微流体和液滴的技术可实现细胞的无偏向分离。不过，需要注意的是，组织/细胞的解离过程可能会改变RNA的表达谱。
RNA-Seq方案 标准的文库制备方案适用于10-100 ng的DNA起始材料。然而，单个细胞平均只含有10 pg的总RNA。因此，RNA提取和文库制备的流程必须经过调整和优化，才能用于单细胞材料。
首先，需要裂解分离出的单细胞，以获得RNA。这个步骤可通过自动化设备完成。当然，细胞裂解和RNA纯化的操作可同时进行。
然后，大多数方案是通过polyA选择来富集mRNA，并利用经过修饰的oligo dT引物来进行逆转录。在逆转录的过程中，有些方案利用独特分子标识符（UMI）对单分子进行标记，这些是随机的六核苷酸，可以更精确地定量单细胞中mRNA分子的初始量。之后，通过体外转录或PCR扩增cDNA，然后将扩增好的cDNA文库用于文库制备和高通量测序。
PCR方法的优点在于能够产生全长cDNA。不过，对于不同片段（如GC含量较高），PCR的效率可能不同，导致文库的覆盖度不均匀。另一方面，体外转录产生的文库能够避免PCR的序列偏向，但有些序列的转录效率低，导致序列drop-out或不完整。
数据分析 由于每个单细胞都是独特的，不可能开展重复实验并评估噪音。因此，必须采取一些质量控制手段，以确保数据的可靠性。专家建议，向每个细胞裂解液中加入已知序列和数量的合成mRNA，如外源RNA对照联盟（ERCC）开发的加标RNA。这些RNA的读数将提供样本间差异的信息。
总的来说，单细胞水平的转录组分析可以揭示细胞群体中的细胞异质性，强调了个别细胞的与众不同。此外，同时分析多种分子（如DNA、RNA和蛋白质）的方法也不断被开发出来。这种更全面的单细胞组图有望进一步加深我们对生物学过程的了解，对未来的科研及临床研究大有裨益。
Data analysis In contrast to bulk RNA-seq, scRNA-seq provides quantitative measurements of the expression of every gene in a single cell.</description>
    </item>
    
    <item>
      <title>Single_cell_sequencing入门</title>
      <link>https://kongjianyang.github.io/cn/2022/05/23/scrna/</link>
      <pubDate>Mon, 23 May 2022 16:03:40 -0600</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2022/05/23/scrna/</guid>
      <description>Single_cell_sequencing入门 // Pandoc 2.9 adds attributes on both header and div. We remove the former (to // be compatible with the behavior of Pandoc :first-child&#34;); var i, h, a; for (i = 0; i 0) h.removeAttribute(a[0].name); } });  /*! jQuery v3.6.0 | (c) OpenJS Foundation and other contributors | jquery.org/license */ !function(e,t){&#34;use strict&#34;;&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return t(e)}:t(e)}(&#34;undefined&#34;!=typeof window?window:this,function(C,e){&#34;use strict&#34;;var t=[],r=Object.</description>
    </item>
    
    <item>
      <title>R语言数据导入rio包</title>
      <link>https://kongjianyang.github.io/cn/2022/03/30/rio/</link>
      <pubDate>Wed, 30 Mar 2022 14:32:27 -0500</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2022/03/30/rio/</guid>
      <description>rio: A Swiss-Army Knife for Data I/O
CRAN - Package rio (r-project.org) 笔记说明 在读《Modern R with the tidyverse》 一书时发现了这个非常好用的R包，做此笔记记录。本笔记记录rio包的数据导入功能。导出功能说明见：用rio包进行数据导出 数据导入 Hadley Wickham在《R for Data Science》中总结的探索性数据分析的分析流程
数据导入是数据分析的第一步。实际工作中数据的来源和原始数据文件的格式多种多样。对应不同的原始文件来源或格式就有很多不同的读取数据的R包。学习、使用起来非常麻烦。在rio包之前，为了满足数据导入需要，大概需要学习的R包和其对应的数据文件类型如下：
 readr包 - text files（如csv, tsv, fwf文件） haven包 - SPSS, Stata, and SAS files readxl包 - excel files DBI包 - databases jsonlite包 - json xml2包 - XML httr包 - Web APIs rvest包 - HTML (Web Scraping)  rio包及其数据导入功能 rio包封装了很多数据导入和导出的包，并将不同包的数据导入导出操作统一到两个函数上：import()和export()，通过文件的后缀名来判断文件类型。这使得在R中进行数据的导入导出操作变得非常简单。有关rio包的更多信息可以参见：https://cran.r-project.org/web/packages/rio/vignettes/rio.html 下面对rio包的一些数据导入功能进行展示（基本参照《Modern R with the tidyverse》中对应的内容，所使用的数据可以在https://github.com/b-rodrigues/modern_R/tree/master/datasets 下载）：</description>
    </item>
    
    <item>
      <title>R语言基于S3的面向对象编程</title>
      <link>https://kongjianyang.github.io/cn/2022/03/29/r_s3/</link>
      <pubDate>Tue, 29 Mar 2022 14:32:27 -0500</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2022/03/29/r_s3/</guid>
      <description>参考这篇文章：
R语言面向对象编程 (dataxujing.github.io) S3对象的介绍 在R语言中，基于S3对象的面向对象编程，是一种基于泛型函数的实现方式。泛型函数是一种特殊的函数，根据传入对象的类型决定调用那个具体的方法。基于S3对象实现面向对象编程，不同其他语言的面型对象编程，是一种动态函数调用的模拟实现。S3对象被广泛应用于R的早期的开发包中。
R的S3系统有三个组成部分:属性(attribute)(尤其是class属性)、泛型函数(genericfunction)和方法(method)
创建S3对象 注意：本文会用到pryr,为了方便我们检查对象的类型，引入pryr包作为辅助工具。
library(pryr) #通过变量创建S3对象 x &amp;lt;- 1 attr(x,&#39;class&#39;) &amp;lt;- &#39;foo&#39; x ## [1] 1 ## attr(,&amp;quot;class&amp;quot;) ## [1] &amp;quot;foo&amp;quot; ## [1] &amp;quot;foo&amp;quot; ## [1] &amp;quot;foo&amp;quot; #用pryr包的otype函数,检查x的类型 otype(x) ## [1] &amp;quot;S3&amp;quot; 通过structure()函数创建S3对象
y &amp;lt;- structure(2,class=&amp;quot;foo&amp;quot;) y ## [1] 2 ## attr(,&amp;quot;class&amp;quot;) ## [1] &amp;quot;foo&amp;quot; ## [1] &amp;quot;foo&amp;quot; ## [1] &amp;quot;foo&amp;quot; ## [1] &amp;quot;S3&amp;quot; 创建一个多类型的S3对象，S3独享没有明确结构关系，一个S3对象可以有多个类型，S3对象的class属性可以是一个向量，包括多种类型
x &amp;lt;- 1 attr(x,&amp;quot;class&amp;quot;) &amp;lt;- c(&amp;quot;foo&amp;quot;,&amp;quot;bar&amp;quot;) # 给了x对象两个class属性 class(x) ## [1] &amp;quot;foo&amp;quot; &amp;quot;bar&amp;quot; ## [1] &amp;quot;S3&amp;quot; 如果分配至少一个class属性，就是S3对象，如果没有class属性，就是base对象。</description>
    </item>
    
    <item>
      <title>MACS2使用</title>
      <link>https://kongjianyang.github.io/cn/2022/03/25/bioinfo/</link>
      <pubDate>Fri, 25 Mar 2022 14:32:27 -0500</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2022/03/25/bioinfo/</guid>
      <description>参考资料：
这可能是最棒的MACS2使用说明 (360doc.com) 使用MACS2进行差异peak分析_生信修炼手册的博客-CSDN博客 MACS2：Model-based analysis of ChiP-Seq. 最初的设计是用来鉴定转录因子的结合位点，但是它也可以用于其他类型的富集方式测序。
MACS2作为使用最广泛的peak calling软件，在v2版本中添加了差异peak分析的功能，所有的子命令功能描述如下
通过bdgdiff子命令来进行差异peak分析， 该命令不需要基于已有的peak calling结果，只需要输入每个样本对应的bedGraph格式的文件。需要注意的是，该命令只针对两个样本间的差异peak进行设计，适用于没有生物学重复的情况。
对于使用macs2来进行差异peak的完整流程，官方给出了详细的说明文档，链接如下
 https://github.com/taoliu/MACS/wiki/Call-differential-binding-events  可以分为以下3步
1. 预测插入片段长度 通过predictd子命令可以预测样本的fragment size，命令如下
macs2 predictd -i input.bam #!/bin/bash module load bioinfo module load biocontainers/default module load macs2/2.2.7.1-py39 for i in `ls [A-H][1-9][A-H][1-9][A-H][1-9].bam`; do msg=&amp;quot;macs2 predictd -i $i&amp;quot;; echo $msg; macs2 predictd -i $i; 2. peak calling 在peak calling时，需要添加-B参数，这样才可以输出样本对应的bedgraph文件，同时需要保证peak calling时采用一致的--extsize的值，就是第一步预测出来的数值，取多个样本的均值即可。官方也给出了推荐值，对于大多数的转录因子chip_seq数据，推荐值为200， 对于大部分组蛋白修饰的chip_seq数据，推荐值为147，命令如下
# condition1 macs2 callpeak -B -t cond1_ChIP.bam -c cond1_Control.bam -n cond1 --nomodel --extsize 147 # condition2 # broad peak calling: macs2 callpeak -B -t cond1_ChIP.</description>
    </item>
    
    <item>
      <title>GSEA富集分析</title>
      <link>https://kongjianyang.github.io/cn/2021/08/13/gsea/</link>
      <pubDate>Fri, 13 Aug 2021 16:03:40 -0600</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2021/08/13/gsea/</guid>
      <description>GSEA富集分析 // Pandoc 2.9 adds attributes on both header and div. We remove the former (to // be compatible with the behavior of Pandoc :first-child&#34;); var i, h, a; for (i = 0; i 0) h.removeAttribute(a[0].name); } });  /*! jQuery v3.6.0 | (c) OpenJS Foundation and other contributors | jquery.org/license */ !function(e,t){&#34;use strict&#34;;&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return t(e)}:t(e)}(&#34;undefined&#34;!=typeof window?window:this,function(C,e){&#34;use strict&#34;;var t=[],r=Object.</description>
    </item>
    
    <item>
      <title>R中的fuzzyjoin包介绍</title>
      <link>https://kongjianyang.github.io/cn/2019/11/12/r_fuzzyjoin/</link>
      <pubDate>Tue, 12 Nov 2019 14:32:27 -0500</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2019/11/12/r_fuzzyjoin/</guid>
      <description>假设字符串x最少需要插入a次、删除b次、替换c次才能与字符串y相同，则x、y之间的 距离 即a、b、c的加权总和。比如将”kitten”转化为”sitting”，需要把“k”替换为“s”，把“e”替换为“i”，并在尾部插入“g”，所以共需1次插入、0次删除、2次替换，按照默认权重两者之间 距离 英该为3。
在R语言中，我们可以使用adist(x, y = NULL, costs = NULL, counts = FALSE, …)的形式，计算字符串之间的距离。其中：
 costs即插入（insertions）、删除（deletions）、替换（substitutions）次数的权重 counts表示是否输出插入、删除、替换次数 partial表示是否只进行局部匹配  library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.3 ✓ purrr 0.3.4 ## ✓ tibble 3.1.1 ✓ dplyr 1.0.5 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() drop(attr(adist(&amp;quot;kitten&amp;quot;, &amp;quot;sitting&amp;quot;, counts = TRUE), &amp;quot;counts&amp;quot;)) ## ins del sub ## 1 0 2 adist(&amp;quot;kitten&amp;quot;, &amp;quot;sitting&amp;quot;, counts = TRUE) %&amp;gt;% attr(.</description>
    </item>
    
    <item>
      <title>使用Rmd写博客的一些流程</title>
      <link>https://kongjianyang.github.io/cn/2018/12/25/rmd/</link>
      <pubDate>Tue, 25 Dec 2018 14:32:27 -0500</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2018/12/25/rmd/</guid>
      <description>首先将Rmd文件转换为md文件
library(rmarkdown) a &amp;lt;- list.files(&amp;quot;./&amp;quot;, pattern = &amp;quot;.Rmd&amp;quot;) map(a, render, md_document()) #会将当前文件下所有的Rmd文件转化为md文件  on the Mac you could use the following commands to open RStudio (respectively) in the &amp;lsquo;~/projects/foo&amp;rsquo; directory or the current working directory:
 $ open -a RStudio ~/projects/foo $ open -a RStudio . 这里的open命令很有用
MacOS用户如果有用命令行的话，大多数人应该知道open .会打开Finder。事实上它能打开所有的目录，比如:
$ open ~/Library/Preferences $ open /etc $ open ../.. 你还能同时打开多个目录：
$ open ~/Documents ~/Desktop ~/Downloads $ open ~/D* 然后它还能打开各种文件，比如：
$ open document.</description>
    </item>
    
    <item>
      <title>z-score标准化和R代码实现</title>
      <link>https://kongjianyang.github.io/cn/2018/11/30/z-score%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8Cr%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kongjianyang.github.io/cn/2018/11/30/z-score%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8Cr%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</guid>
      <description>z-score标准化：标准分数（standard score）也叫z分数（z-score）,是一个分数与平均数的差再除以标准差的过程。 用公式表示为：z=(x-μ)/σ。或者说Z = (x - x(mean)) / x(sd)，其中x为某一具体分数，μ为平均数，σ为标准差。 Z值代表着原始分数和母体平均值之间的距离，是以标准差为单位计算。 标准分数可以回答这样一个问题：“一个给定分数距离平均数多少个标准差?”在平均数之上的分数会得到一个正的标准分数，在平均数之下的分数会得到一个负的标准分数。 经过处理的数据符合标准正态分布，即均值为0，标准差为1， Z score 也可以用来表示组织特异性，0 表示没有组织特异性， Z-score &amp;gt;3 表示组织特异性强
z-score标准化也叫做标准差标准化，经过处理之后的数据会符合标准正态分布，其均值为0，标准差为1。
z-score标准化方法适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。其他还有
 最小-最大规范化——标准化：对原始数据的线性变换，将数据映射到[0,1]之间 x-min(x) / max(x)-min(x) 移动变量的小数点位置来将变量映射到[-1,1]  data &amp;lt;- matrix(1:16,nrow=4) data ## [,1] [,2] [,3] [,4] ## [1,] 1 5 9 13 ## [2,] 2 6 10 14 ## [3,] 3 7 11 15 ## [4,] 4 8 12 16 函数density计算的是数据的核心密度（kernal density）分布，其中density的计算可以通过bw参数（bandwidth）来控制，bw参数最直观的影响就是曲线的平滑性。默认的bw是通过函数bw.nrd0()计算得出，也可以手动设置。
d&amp;lt;-density(data) plot(d) a&amp;lt;-round(scale(data),2) a ## [,1] [,2] [,3] [,4] ## [1,] -1.</description>
    </item>
    
    <item>
      <title>Add p value and significant marker for ggplot based on ggpubr</title>
      <link>https://kongjianyang.github.io/en/2018/06/07/add-p-value-and-significant-marker-for-ggplot-based-on-ggpubr/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kongjianyang.github.io/en/2018/06/07/add-p-value-and-significant-marker-for-ggplot-based-on-ggpubr/</guid>
      <description>The ‘ggpubr’ package provides some easy-to-use functions for creating and customizing ‘ggplot2’- based publication ready plots. -A. Kassambara.
 Reference
1. Preparation install the package
install.packages(&amp;quot;ggpubr&amp;quot;) or you can install the latest version form github
if(!require(devtools)) install.packages(&amp;quot;devtools&amp;quot;) # if havn`t install devtools before, install it first devtools::install_github(&amp;quot;kassambara/ggpubr&amp;quot;) load package
library(ggpubr) load data
data(&amp;quot;ToothGrowth&amp;quot;) head(ToothGrowth) ## len supp dose ## 1 4.2 VC 0.5 ## 2 11.5 VC 0.5 ## 3 7.</description>
    </item>
    
  </channel>
</rss>
